{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294350a8-58f6-4a41-adc9-d4e6bce24f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/dnanexus/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting transformers==4.2\n",
      "  Downloading transformers-4.2.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m132.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m277.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.10.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.3/773.3 kB\u001b[0m \u001b[31m345.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from transformers==4.2) (1.23.5)\n",
      "Collecting tokenizers==0.9.4\n",
      "  Downloading tokenizers-0.9.4-cp39-cp39-manylinux2010_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m251.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from transformers==4.2) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.2) (4.65.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.2) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.2) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.2) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.2) (1.26.15)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers==4.2) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers==4.2) (8.1.7)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m326.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=bbacbea935540b174dfae5e5a744086a01b96a08581ec3c984f49b1f2a68eae4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zxicoapw/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, regex, joblib, filelock, sacremoses, transformers\n",
      "Successfully installed filelock-3.12.4 joblib-1.3.2 regex-2023.10.3 sacremoses-0.0.53 tokenizers-0.9.4 transformers-4.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers==4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea46c9f-8a9d-422b-b6d8-669358c68d04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/dnanexus/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch\n",
      "  Downloading torch-2.1.0-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m263.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m267.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting flax\n",
      "  Downloading flax-0.7.4-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m315.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m256.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m243.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0\n",
      "  Downloading triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 MB\u001b[0m \u001b[31m214.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m366.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m301.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch) (3.12.4)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m297.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m294.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m268.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m242.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m208.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m279.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m249.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m262.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m340.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m265.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m306.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m265.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m263.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m269.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m324.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m250.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.15,>=2.14\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m281.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m332.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes==0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m291.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m157.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow) (23.0)\n",
      "Collecting keras<2.15,>=2.14.0\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m254.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m287.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.23.5)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m164.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting msgpack\n",
      "  Downloading msgpack-1.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (530 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.0/531.0 kB\u001b[0m \u001b[31m327.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jax>=0.4.2\n",
      "  Downloading jax-0.4.19-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m319.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optax\n",
      "  Downloading optax-0.1.7-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m290.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orbax-checkpoint\n",
      "  Downloading orbax_checkpoint-0.4.1-py3-none-any.whl (113 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m297.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /opt/conda/lib/python3.9/site-packages (from flax) (5.4.1)\n",
      "Collecting rich>=11.1\n",
      "  Downloading rich-13.6.0-py3-none-any.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.8/239.8 kB\u001b[0m \u001b[31m313.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorstore\n",
      "  Downloading tensorstore-0.1.46-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m194.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.9/site-packages (from jax>=0.4.2->flax) (1.9.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /opt/conda/lib/python3.9/site-packages (from jax>=0.4.2->flax) (6.8.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from rich>=11.1->flax) (2.16.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m280.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m269.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.28.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.5-py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m205.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.0-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.6/226.6 kB\u001b[0m \u001b[31m309.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m310.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Collecting chex>=0.1.5\n",
      "  Downloading chex-0.1.84-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m277.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jaxlib>=0.1.37\n",
      "  Downloading jaxlib-0.4.19-cp39-cp39-manylinux2014_x86_64.whl (85.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 MB\u001b[0m \u001b[31m187.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nest_asyncio in /opt/conda/lib/python3.9/site-packages (from orbax-checkpoint->flax) (1.5.6)\n",
      "Collecting etils[epath,epy]\n",
      "  Downloading etils-1.5.1-py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.5/140.5 kB\u001b[0m \u001b[31m309.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorstore\n",
      "  Downloading tensorstore-0.1.45-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m152.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m349.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: toolz>=0.9.0 in /opt/conda/lib/python3.9/site-packages (from chex>=0.1.5->optax->flax) (0.12.0)\n",
      "Collecting numpy>=1.23.5\n",
      "  Downloading numpy-1.26.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m227.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m313.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.6->jax>=0.4.2->flax) (3.16.2)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (1.26.15)\n",
      "Collecting numpy>=1.23.5\n",
      "  Downloading numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m282.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.9/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.0.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m256.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m319.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, libclang, flatbuffers, wrapt, werkzeug, triton, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, sympy, pyasn1, protobuf, oauthlib, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, msgpack, mdurl, keras, grpcio, google-pasta, gast, fsspec, etils, cachetools, astunparse, absl-py, tensorstore, rsa, requests-oauthlib, pyasn1-modules, opt-einsum, nvidia-cusparse-cu12, nvidia-cudnn-cu12, ml-dtypes, markdown-it-py, markdown, h5py, rich, nvidia-cusolver-cu12, jaxlib, jax, google-auth, torch, orbax-checkpoint, google-auth-oauthlib, chex, tensorboard, optax, tensorflow, flax\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dxdata 0.39.0 requires numpy==1.23.5; python_version >= \"3.8\", but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.1 chex-0.1.84 etils-1.5.1 flatbuffers-23.5.26 flax-0.7.4 fsspec-2023.9.2 gast-0.5.4 google-auth-2.23.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 h5py-3.10.0 jax-0.4.19 jaxlib-0.4.19 keras-2.14.0 libclang-16.0.6 markdown-3.5 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.2.0 mpmath-1.3.0 msgpack-1.0.7 numpy-1.25.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.1.105 oauthlib-3.2.2 opt-einsum-3.3.0 optax-0.1.7 orbax-checkpoint-0.4.1 protobuf-4.24.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rich-13.6.0 rsa-4.9 sympy-1.12 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.34.0 tensorstore-0.1.45 termcolor-2.3.0 torch-2.1.0 triton-2.1.0 werkzeug-3.0.0 wrapt-1.14.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch tensorflow flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba12623-999e-4553-8006-422124c9e997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84d75d8-9f76-4bf0-ad4e-8a462d7b9936",
   "metadata": {},
   "source": [
    "Build a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e14d71-5eb9-4332-b3b5-dff996701041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VectorDatabase:\n",
    "    def __init__(self):\n",
    "        self.vectors = defaultdict(np.ndarray)\n",
    "\n",
    "    def insert(self, key: str, vector: np.ndarray) -> None:\n",
    "        self.vectors[key] = vector\n",
    "\n",
    "    def search(self, query_vector: np.ndarray, k: int) -> List[Tuple[str, float]]:\n",
    "        similarities = [(key, cosine(query_vector, vector)) for key, vector in self.vectors.items()]\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return similarities[:k]\n",
    "\n",
    "    def retrieve(self, key: str) -> np.ndarray:\n",
    "        return self.vectors.get(key, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73d8dd5-37cf-4dc8-a09a-73630f67c691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine(v1: np.ndarray, v2: np.ndarray) -> float:\n",
    "    result = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1501ffb1-c91b-4177-b2d3-7219111bdd15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get embeddings from the file\n",
    "df = pd.read_csv(\"cord_19_embeddings_2022-06-02_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71e17a5f-0e16-47d6-add5-588dd279ae60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a vector database\n",
    "vector_db = VectorDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849e890-25c6-479f-b4cc-54fcc376fa34",
   "metadata": {},
   "source": [
    "Embed the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59f6ccad-e1e4-4a66-863c-ac6a7dde3047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b47e689cb041e9996a27e98c077528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d69666c29b446cbdc142a62bce6f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/222k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266896f6fa784d609a419980cebcbba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683bcb6113f440a18c6d003cd6b07ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/321 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c08cd4d2364bc9ae4009666182aa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/specter')\n",
    "model = AutoModel.from_pretrained('allenai/specter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62ef1219-29ba-488c-877e-589d4e24397f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "papers = [\n",
    "    {'title': 'BERT', 'abstract': 'We introduce a new language representation model called BERT'},\n",
    "    {'title': 'Attention is all you need', 'abstract': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks'},\n",
    "    {'title': 'ImageNet Classification with Deep Convolutional Neural Networks', 'abstract': 'We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest.'},\n",
    "    {'title': 'Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm', 'abstract': 'The game of chess is the most widely-studied domain in the history of artificial intelligence. We introduce an algorithm based purely on reinforcement learning, without human data.'},\n",
    "    {'title': 'Playing Atari with Deep Reinforcement Learning', 'abstract': 'We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning.'},\n",
    "    {'title': 'Gradient-based learning applied to document recognition', 'abstract': 'Procedures for training the multi-layer perceptron are discussed in a comprehensive framework.'},\n",
    "    {'title': 'Understanding Machine Learning: From Theory to Algorithms', 'abstract': 'This book provides a theoretical account of the fundamentals underlying machine learning and the mathematical derivations that transform these principles into practical algorithms.'},\n",
    "    {'title': 'A Few Useful Things to Know About Machine Learning', 'abstract': 'This paper provides a general, high-level overview of important concepts in machine learning.'},\n",
    "    {'title': 'Dropout: A Simple Way to Prevent Neural Networks from Overfitting', 'abstract': 'Dropout is a technique for addressing the overfitting problem in large neural networks.'},\n",
    "    {'title': 'Sequence to Sequence Learning with Neural Networks', 'abstract': 'We propose a deep learning approach for translating short sentences using neural networks.'},\n",
    "    {'title': 'Word2Vec', 'abstract': 'We propose two novel model architectures for computing continuous vector representations of words from very large data sets.'},\n",
    "    {'title': 'Zero-shot learning with semantic output codes', 'abstract': 'Zero-shot learning is a paradigm which bypasses the need for labeled examples for each possible class.'},\n",
    "    {'title': 'Neural Machine Translation by Jointly Learning to Align and Translate', 'abstract': 'We propose a novel neural network architecture for machine translation that models the alignment between source and target sequences.'},\n",
    "    {'title': 'Deep Residual Learning for Image Recognition', 'abstract': 'Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously.'},\n",
    "    {'title': 'Generative Adversarial Networks', 'abstract': 'We propose a new framework for estimating generative models via an adversarial process.'},\n",
    "    {'title': 'FaceNet: A Unified Embedding for Face Recognition and Clustering', 'abstract': 'We present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space.'},\n",
    "    {'title': 'YOLO: You Only Look Once', 'abstract': 'We present YOLO, a new approach to object detection. Our model makes a single look at an image and predicts what objects are present and where they are.'},\n",
    "    {'title': 'Style Transfer', 'abstract': 'We present an approach to rapidly and easily generate a wide variety of image styles from a single input image.'},\n",
    "    {'title': 'Graph Neural Networks', 'abstract': 'We propose a novel type of neural network model for processing structured data with graph.'},\n",
    "    {'title': 'The Transformer Family: A Survey', 'abstract': 'This paper surveys the various models that have been introduced based on the Transformer architecture and its applications.'},\n",
    "    \n",
    "    {'title': 'Molecular Structure of Nucleic Acids', 'abstract': 'A structure for deoxyribose nucleic acid (DNA). Watson and Crick propose the double helix model of DNA.'},\n",
    "    {'title': 'The Sequence of the Human Genome', 'abstract': 'An initial draft and analysis of the human genome, revealing the vast amount of information encoded within our DNA.'},\n",
    "    {'title': 'Genome sequence of the nematode C. elegans: A platform for investigating biology', 'abstract': 'The complete genome sequence of the nematode Caenorhabditis elegans offers insights into animal biology and evolution.'},\n",
    "    {'title': 'RNA interference: traveling in the cell and gaining functions?', 'abstract': 'A review of RNA interference (RNAi) mechanisms, its cellular applications, and functional gains.'},\n",
    "    {'title': 'DNA methylation and gene function', 'abstract': 'Exploring the relationship between DNA methylation patterns and gene function.'},\n",
    "    {'title': 'The Hallmarks of Cancer', 'abstract': 'The complexities of cancer biology are distilled into a set of underlying principles, shedding light on cancer biological properties.'},\n",
    "    {'title': 'Splicing in the Inner Ear: A Familiar Tune, but What Are the Instruments?', 'abstract': 'Insights into alternative splicing events in the inner ear.'},\n",
    "    {'title': 'Principles of microRNA–target recognition', 'abstract': 'Exploring the principles governing the recognition of target mRNAs by miRNAs.'},\n",
    "    {'title': 'The Polymerase Chain Reaction', 'abstract': 'Introduction and exploration of the PCR technique, a foundational method for amplifying DNA.'},\n",
    "    {'title': 'Targeting of the CREB gene leads to up-regulation of a novel CREB mRNA isoform', 'abstract': 'Insights into gene targeting and the role of CREB in transcription.'},\n",
    "    {'title': 'The Unfolded Protein Response: From Stress Pathway to Homeostatic Regulation', 'abstract': 'Understanding the UPR and its role in maintaining cellular homeostasis.'},\n",
    "    {'title': 'Mechanisms and Functions of DNA Mismatch Repair', 'abstract': 'A comprehensive review of DNA mismatch repair and its implications in genomic stability.'},\n",
    "    {'title': 'The Genomic Basis of Adaptive Evolution in Threespine Sticklebacks', 'abstract': 'Exploring the genomic changes accompanying adaptation in stickleback fish.'},\n",
    "    {'title': 'MicroRNAs: genomics, biogenesis, mechanism, and function', 'abstract': 'A comprehensive review of microRNAs, their genesis, and function in gene regulation.'},\n",
    "    {'title': 'Clonal expansion of mutated mitochondrial DNA is associated with tumor formation and complex I deficiency in the benign renal oncocytoma', 'abstract': 'Unraveling the role of mitochondrial DNA mutations in benign renal oncocytoma.'},\n",
    "    {'title': 'The Structure of the Potassium Channel: Molecular Basis of K+ Conduction and Selectivity', 'abstract': 'Detailed insights into the structure and function of potassium ion channels.'},\n",
    "    {'title': 'Telomeres and Telomerase: The Path from Maize, Tetrahymena and Yeast to Human Cancer and Aging', 'abstract': 'Understanding the role and function of telomeres and telomerase in aging and cancer.'},\n",
    "    {'title': 'Tracing the origins of functional and conserved domains in the human genome: implications for protein evolution', 'abstract': 'Investigating the evolutionary origins of functional domains in human proteins.'},\n",
    "    {'title': 'Transcriptional regulatory code of a eukaryotic genome', 'abstract': 'Deciphering the regulatory code governing transcription in eukaryotes.'},\n",
    "    {'title': 'The Tumor Microenvironment and Immune Milieu of Cholangiocarcinoma', 'abstract': 'Understanding the complex interplay between tumors and the immune system in cholangiocarcinoma.'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "807a0297-648e-4b6e-acc6-a3bd50b755db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concatenate title and abstract\n",
    "title_abs = [d['title'] + tokenizer.sep_token + (d.get('abstract') or '') for d in papers]\n",
    "# preprocess the input\n",
    "inputs = tokenizer(title_abs, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "result = model(**inputs)\n",
    "# take the first token in the batch as the embedding\n",
    "embeddings = result.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f788b9c-cd60-487a-afbe-68d199eda9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85b86fae-b5f6-4962-b39c-4ba4e9593d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CURRENTLY IT WILL INSERT INTO THE ALREADY EXISTING DATABASE, BUT IT SHOULDN'T MATTER\n",
    "keys = np.random.randint(1000, size=40)\n",
    "# insert embeddings into the database\n",
    "for i, row in enumerate(embeddings):\n",
    "    key = keys[i]\n",
    "    embedding = embeddings[i]\n",
    "    embedding = embedding.detach().numpy()    \n",
    "    vector_db.insert(key, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bf7ce6a-19b6-4800-9210-fba41c5c59a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"The Hallmarks of Cancer\"\n",
    "inputs = tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "result = model(**inputs)\n",
    "query_embedding = result.last_hidden_state[:, 0, :]\n",
    "query_embedding = query_embedding.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fa514bb-a465-40ad-aa50-b9d8adfecd92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.01 ms, sys: 0 ns, total: 3.01 ms\n",
      "Wall time: 2.27 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(664, array([0.9816665], dtype=float32)),\n",
       " (487, array([0.86776626], dtype=float32)),\n",
       " (496, array([0.8626136], dtype=float32)),\n",
       " (638, array([0.8496898], dtype=float32)),\n",
       " (627, array([0.8356982], dtype=float32))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "result = vector_db.search(query_embedding, k=5)\n",
    "result # result will give the key for the best matched paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb773846-625a-4453-adfc-1bedb6188bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_result = result[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "018a8ed0-1315-40fe-a48e-73f2369c4576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_in_papers = list(keys).index(best_result) # this will give the index of that paper in the papers array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77ea5935-9fb1-4a17-8ce5-e74719b48394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Understanding Machine Learning: From Theory to Algorithms',\n",
       " 'abstract': 'This book provides a theoretical account of the fundamentals underlying machine learning and the mathematical derivations that transform these principles into practical algorithms.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[index_in_papers] # now find out the title and abstract of the found paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f2a3b-0a6b-4a18-900a-2911be2f6778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
